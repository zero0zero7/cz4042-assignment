{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jnRX6LUnqBpw"
   },
   "source": [
    "CS4001/4042 Assignment 1, Part B, Q1\n",
    "---\n",
    "\n",
    "Real world datasets often have a mix of numeric and categorical features – this dataset is one example. To build models on such data, categorical features have to be encoded or embedded.\n",
    "\n",
    "PyTorch Tabular is a library that makes it very convenient to build neural networks for tabular data. It is built on top of PyTorch Lightning, which abstracts away boilerplate model training code and makes it easy to integrate other tools, e.g. TensorBoard for experiment tracking.\n",
    "\n",
    "For questions B1 and B2, the following features should be used:   \n",
    "- **Numeric / Continuous** features: dist_to_nearest_stn, dist_to_dhoby, degree_centrality, eigenvector_centrality, remaining_lease_years, floor_area_sqm\n",
    "- **Categorical** features: month, town, flat_model_type, storey_range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kn0j2MRKqKVs"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jA67PbIY3PnH"
   },
   "outputs": [],
   "source": [
    "!pip install pytorch_tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jr6P3U7w3NVl"
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "import os\n",
    "\n",
    "import random\n",
    "random.seed(SEED)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(SEED)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.models import CategoryEmbeddingModelConfig\n",
    "from pytorch_tabular.config import (\n",
    "    DataConfig,\n",
    "    OptimizerConfig,\n",
    "    TrainerConfig,\n",
    ")\n",
    "\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zGyEWcVlqKTz"
   },
   "source": [
    "> Divide the dataset (‘hdb_price_prediction.csv’) into train, validation and test sets by using entries from year 2019 and before as training data, year 2020 as validation data and year 2021 as test data.\n",
    "**Do not** use data from year 2022 and year 2023.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hoCPcOWupw5Y"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('hdb_price_prediction.csv')\n",
    "\n",
    "# TODO: Enter your code here\n",
    "train_df = df[df['year'] <= 2019]\n",
    "val_df = df[df['year'] == 2020]\n",
    "test_df = df[df['year'] == 2021]\n",
    "\n",
    "# Remove the features not used to train the model\n",
    "train_df = train_df.drop(columns = ['year', 'nearest_stn', 'full_address'])\n",
    "val_df = val_df.drop(columns = ['year', 'nearest_stn', 'full_address'])\n",
    "test_df = test_df.drop(columns = ['year', 'nearest_stn', 'full_address'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sebMgSuzqPe7"
   },
   "source": [
    "> Refer to the documentation of **PyTorch Tabular** and perform the following tasks: https://pytorch-tabular.readthedocs.io/en/latest/#usage\n",
    "- Use **[DataConfig](https://pytorch-tabular.readthedocs.io/en/latest/data/)** to define the target variable, as well as the names of the continuous and categorical variables.\n",
    "- Use **[TrainerConfig](https://pytorch-tabular.readthedocs.io/en/latest/training/)** to automatically tune the learning rate. Set batch_size to be 1024 and set max_epoch as 50.\n",
    "- Use **[CategoryEmbeddingModelConfig](https://pytorch-tabular.readthedocs.io/en/latest/models/#category-embedding-model)** to create a feedforward neural network with 1 hidden layer containing 50 neurons.\n",
    "- Use **[OptimizerConfig](https://pytorch-tabular.readthedocs.io/en/latest/optimizer/)** to choose Adam optimiser. There is no need to set the learning rate (since it will be tuned automatically) nor scheduler.\n",
    "- Use **[TabularModel](https://pytorch-tabular.readthedocs.io/en/latest/tabular_model/)** to initialise the model and put all the configs together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZZWAYdNhqPzh"
   },
   "outputs": [],
   "source": [
    "# TODO: Enter your code here\n",
    "\n",
    "data_config = DataConfig(\n",
    "\ttarget=[\"resale_price\"],\n",
    "\tcontinuous_cols=[\"dist_to_nearest_stn\", \"dist_to_dhoby\", \"degree_centrality\", \"eigenvector_centrality\", \"remaining_lease_years\", \"floor_area_sqm\"],\n",
    "\tcategorical_cols=[\"month\", \"town\", \"flat_model_type\", \"storey_range\"],\n",
    ")\n",
    "\n",
    "trainer_config = TrainerConfig(batch_size=1024, max_epochs=50)\n",
    "\n",
    "model_config = CategoryEmbeddingModelConfig(\n",
    "\ttask=\"regression\",\n",
    "\tlayers=\"50\",  # Number of nodes in hidden layer\n",
    ")\n",
    "\n",
    "optimizer_config = OptimizerConfig(\n",
    "    optimizer=\"Adam\"\n",
    ")\n",
    "\n",
    "tabular_model = TabularModel(\n",
    "\tdata_config=data_config,\n",
    "\tmodel_config=model_config,\n",
    "\toptimizer_config=optimizer_config,\n",
    "\ttrainer_config=trainer_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model\n",
    "tabular_model.fit(train=train_df, validation=val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = tabular_model.evaluate(test_df)\n",
    "pred_df = tabular_model.predict(test_df)\n",
    "list(pred_df['resale_price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = result[0]['test_mean_squared_error']\n",
    "rsme = math.sqrt(mse)\n",
    "\n",
    "r2 = r2_score(y_true = list(pred_df['resale_price']), y_pred = list(pred_df['resale_price_prediction']))\n",
    "\n",
    "print(\"Root Mean Squared Error: \", rsme)\n",
    "print(\"R2 Score: \", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-2UXPKq0qWQG"
   },
   "source": [
    "> Report the test RMSE error and the test R2 value that you obtained.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zmE9Bc7Nqadi"
   },
   "source": [
    "\\# TODO: \\<Enter your answer here\\>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NEJhRU18qX22"
   },
   "source": [
    "> Print out the corresponding rows in the dataframe for the top 25 test samples with the largest errors. Identify a trend in these poor predictions and suggest a way to reduce these errors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5ma5K9vKqZEq"
   },
   "outputs": [],
   "source": [
    "# TODO: Enter your code here\n",
    "pred_df[\"error\"] = (pred_df[\"resale_price\"] - pred_df[\"resale_price_prediction\"]).abs()\n",
    "sorted_df = pred_df.sort_values(by=[\"error\"], ascending=False)\n",
    "sorted_df.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bX5zy7V3qaGp"
   },
   "source": [
    "\\# TODO: \\<Enter your answer here\\> <br />\n",
    "These rows all have a degree_centrality of 0.016807. <br />\n",
    "We can reduce the weight of the neuron in charge of this degree_centrality feature."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOG8ZhA98h3O6fnefkjOU9w",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
